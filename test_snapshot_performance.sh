#!/bin/bash

# ==============================================================================
# GaussDB CDC Snapshot Performance Test
# æµ‹è¯•å¿«ç…§é˜¶æ®µçš„å†™å…¥æ€§èƒ½ - 10,000 æ¡è®°å½•
# ==============================================================================

set -e

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
MAGENTA='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m'

SCRIPT_DIR=$(dirname "$0")

# DN Connection Details
DN_HOSTS=("10.250.0.30" "10.250.0.181" "10.250.0.157")
DN_PORTS=("40000" "40020" "40040")

# CN Connection Details
CN_HOST="10.250.0.30"
CN_PORT="8000"
DB_USER="tom"
DB_PASS="Gauss_235"
DB_NAME="db1"

# æ€§èƒ½æµ‹è¯•å‚æ•°
TOTAL_RECORDS=100000
BATCH_SIZE=1000


SOURCE_TABLE="products"
SINK_TABLE="products_sink"

# PSQL Command wrapper
function run_sql_cn() {
    local sql="$1"
    local silent="${2:-false}"
    
    if [ "$silent" != "true" ]; then
        echo -e "${BLUE}[CN] $sql${NC}"
    fi
    PGPASSWORD=$DB_PASS psql -h $CN_HOST -p $CN_PORT -U $DB_USER -d $DB_NAME -c "$sql" 2>&1
}

# è·å– sink è¡¨è®°å½•æ•°
function get_sink_count() {
    PGPASSWORD=$DB_PASS psql -h $CN_HOST -p $CN_PORT -U $DB_USER -d $DB_NAME -t -A -c "SELECT COUNT(*) FROM $SINK_TABLE;" 2>/dev/null | tr -cd '0-9'
}

# å–æ¶ˆæ‰€æœ‰è¿è¡Œä¸­çš„ Flink Jobs
function cancel_flink_jobs() {
    echo -e "${YELLOW}ğŸ›‘ Cancelling all running Flink jobs...${NC}"
    
    # è·å–æ‰€æœ‰è¿è¡Œä¸­çš„ job ID
    local jobs=$(docker exec flink-jobmanager /opt/flink/bin/flink list 2>/dev/null | grep "RUNNING" | awk '{print $4}')
    
    if [ -n "$jobs" ]; then
        for job_id in $jobs; do
            echo -e "  Cancelling job: $job_id"
            docker exec flink-jobmanager /opt/flink/bin/flink cancel $job_id > /dev/null 2>&1 || true
        done
        echo -e "  Waiting 5s for jobs to terminate..."
        sleep 5
    else
        echo -e "  No running jobs found"
    fi
}

# æ¸…ç†ç°æœ‰æ•°æ®
function cleanup_data() {
    echo -e "${YELLOW}ğŸ§¹ Cleaning up existing data...${NC}"
    
    # å…ˆå–æ¶ˆ Flink jobsï¼Œé¿å…ç«æ€æ¡ä»¶
    cancel_flink_jobs
    
    run_sql_cn "TRUNCATE TABLE $SOURCE_TABLE;" true > /dev/null 2>&1 || true
    run_sql_cn "TRUNCATE TABLE $SINK_TABLE;" true > /dev/null 2>&1 || true
    echo -e "${GREEN}âœ… Data cleaned${NC}"
}


# æ¸…ç†å¤åˆ¶æ§½
function cleanup_slots() {
    echo -e "${YELLOW}ğŸ§¹ Cleaning up replication slots on all DNs...${NC}"
    for i in "${!DN_HOSTS[@]}"; do
        local host="${DN_HOSTS[$i]}"
        local port="${DN_PORTS[$i]}"
        
        local slots=$(PGPASSWORD=$DB_PASS psql -h "$host" -p "$port" -U $DB_USER -d $DB_NAME -t -A -c "SELECT slot_name FROM pg_replication_slots WHERE slot_name LIKE 'flink_cdc%';" 2>/dev/null)
        
        for slot in $slots; do
            PGPASSWORD=$DB_PASS psql -h "$host" -p "$port" -U $DB_USER -d $DB_NAME -c "SELECT pg_drop_replication_slot('$slot');" > /dev/null 2>&1 || true
        done
    done
    echo -e "${GREEN}âœ… Slots cleaned${NC}"
}

# æ’å…¥æµ‹è¯•æ•°æ® (æ‰¹é‡æ’å…¥ä¼˜åŒ–)
function insert_test_data() {
    echo -e "${CYAN}ğŸ“Š Inserting $TOTAL_RECORDS test records in batches of $BATCH_SIZE...${NC}"
    
    local start_time=$(date +%s.%N)
    local failed_batches=0
    
    for ((batch_start=1; batch_start<=TOTAL_RECORDS; batch_start+=BATCH_SIZE)); do
        local batch_end=$((batch_start + BATCH_SIZE - 1))
        if [ $batch_end -gt $TOTAL_RECORDS ]; then
            batch_end=$TOTAL_RECORDS
        fi
        
        # æ„å»ºæ‰¹é‡ INSERT è¯­å¥
        local values=""
        for ((id=batch_start; id<=batch_end; id++)); do
            if [ -n "$values" ]; then
                values="$values,"
            fi
            values="$values($id, 'Product $id', 'PERF_TEST', $((id % 1000)).99, $((id % 100)))"
        done
        
        # æ‰§è¡Œæ’å…¥å¹¶æ£€æŸ¥ç»“æœ
        local result=$(PGPASSWORD=$DB_PASS psql -h $CN_HOST -p $CN_PORT -U $DB_USER -d $DB_NAME -c \
            "INSERT INTO $SOURCE_TABLE (product_id, product_name, category, price, stock) VALUES $values;" 2>&1)
        
        if [[ ! "$result" =~ "INSERT" ]]; then
            echo -e "\n${RED}Failed batch $batch_start-$batch_end: $result${NC}"
            failed_batches=$((failed_batches + 1))
        fi
        
        echo -ne "  Progress: $batch_end/$TOTAL_RECORDS records inserted\r"
    done
    
    local end_time=$(date +%s.%N)
    local duration=$(echo "$end_time - $start_time" | bc)
    
    # éªŒè¯å®é™…æ’å…¥çš„è®°å½•æ•°
    echo ""
    echo -e "${YELLOW}  Verifying inserted records...${NC}"
    local actual_count=$(PGPASSWORD=$DB_PASS psql -h $CN_HOST -p $CN_PORT -U $DB_USER -d $DB_NAME -t -A -c "SELECT COUNT(*) FROM $SOURCE_TABLE;" 2>/dev/null)
    
    if [ "$actual_count" -ne "$TOTAL_RECORDS" ]; then
        echo -e "${RED}âŒ DATA INTEGRITY ERROR: Expected $TOTAL_RECORDS, but only $actual_count records in source!${NC}"
        echo -e "${RED}  Attempting to find and insert missing records...${NC}"
        
        # æ‰¾å‡ºç¼ºå¤±çš„ ID å¹¶é‡æ–°æ’å…¥
        local missing=$(PGPASSWORD=$DB_PASS psql -h $CN_HOST -p $CN_PORT -U $DB_USER -d $DB_NAME -t -A -c "
            WITH expected AS (SELECT generate_series(1, $TOTAL_RECORDS) AS id)
            SELECT e.id FROM expected e
            LEFT JOIN $SOURCE_TABLE p ON e.id = p.product_id
            WHERE p.product_id IS NULL;" 2>/dev/null)
        
        for mid in $missing; do
            PGPASSWORD=$DB_PASS psql -h $CN_HOST -p $CN_PORT -U $DB_USER -d $DB_NAME -c \
                "INSERT INTO $SOURCE_TABLE (product_id, product_name, category, price, stock) VALUES ($mid, 'Product $mid', 'PERF_TEST', $((mid % 1000)).99, $((mid % 100)));" > /dev/null 2>&1
        done
        
        # å†æ¬¡éªŒè¯
        actual_count=$(PGPASSWORD=$DB_PASS psql -h $CN_HOST -p $CN_PORT -U $DB_USER -d $DB_NAME -t -A -c "SELECT COUNT(*) FROM $SOURCE_TABLE;" 2>/dev/null)
        echo -e "${GREEN}  After repair: $actual_count records${NC}"
    fi
    
    local insert_rate=$(echo "scale=2; $actual_count / $duration" | bc)
    echo -e "${GREEN}âœ… Verified $actual_count records in source table (${duration}s, ${insert_rate} records/s)${NC}"
    
    if [ "$actual_count" -ne "$TOTAL_RECORDS" ]; then
        echo -e "${RED}âŒ CRITICAL: Still missing records after repair!${NC}"
        return 1
    fi
}


# éªŒè¯æ•°æ®åˆ†å¸ƒ
function verify_data_distribution() {
    echo -e "${CYAN}ğŸ“Š Verifying data distribution across DNs...${NC}"
    local total=0
    for i in "${!DN_HOSTS[@]}"; do
        local host="${DN_HOSTS[$i]}"
        local port="${DN_PORTS[$i]}"
        local count=$(PGPASSWORD=$DB_PASS psql -h "$host" -p "$port" -U $DB_USER -d $DB_NAME -t -A -c "SELECT COUNT(*) FROM $SOURCE_TABLE;" 2>/dev/null)
        echo -e "  DN$((i+1)) ($host:$port): $count records"
        total=$((total + count))
    done
    echo -e "  ${GREEN}Total: $total records${NC}"
}

# éƒ¨ç½² Flink CDC Job
function deploy_flink_job() {
    echo -e "${CYAN}ğŸš€ Deploying Flink CDC Job...${NC}"
    
    # ä½¿ç”¨ç°æœ‰çš„éƒ¨ç½²è„šæœ¬
    SQL_FILE=flink-cdc-connect/flink-cdc-source-connectors/flink-connector-gaussdb-cdc/docker/sql/gaussdb_simplified_sync.sql \
        bash deploy_gaussdb_to_gaussdb.sh 2>&1 | tail -n 20
    
    echo -e "${GREEN}âœ… Flink CDC Job deployed${NC}"
}

# ç›‘æ§å¿«ç…§åŒæ­¥æ€§èƒ½
function monitor_snapshot_sync() {
    echo -e "${MAGENTA}â±ï¸  Monitoring snapshot sync performance...${NC}"
    
    # è·å–æºè¡¨çš„å®é™…è®°å½•æ•°ä½œä¸ºç›®æ ‡
    local source_count=$(PGPASSWORD=$DB_PASS psql -h $CN_HOST -p $CN_PORT -U $DB_USER -d $DB_NAME -t -A -c "SELECT COUNT(*) FROM $SOURCE_TABLE;" 2>/dev/null)
    echo -e "  Source table has: $source_count records"
    
    local start_time=$(date +%s.%N)
    local last_count=0
    local max_wait=1800  # 30 åˆ†é’Ÿè¶…æ—¶ (for 100k records)
    local waited=0
    local check_interval=5

    
    echo -e "  Target: $source_count records (from source)"
    echo ""
    
    while [ $waited -lt $max_wait ]; do
        local current_count=$(get_sink_count)
        
        if [[ -z "$current_count" ]]; then
            current_count=0
        fi

        
        local elapsed=$(echo "$(date +%s.%N) - $start_time" | bc)
        local rate=0
        if (( $(echo "$elapsed > 0" | bc -l) )); then
            rate=$(echo "scale=2; $current_count / $elapsed" | bc)
        fi
        
        # è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯” (åŸºäºæºè¡¨å®é™…è®°å½•æ•°)
        local progress=$((current_count * 100 / source_count))
        
        # æ˜¾ç¤ºè¿›åº¦æ¡
        printf "\r  [%-50s] %3d%% | %d/%d records | %.2f records/s | %.1fs elapsed" \
            "$(printf '#%.0s' $(seq 1 $((progress / 2))))" \
            "$progress" "$current_count" "$source_count" "$rate" "$elapsed"
        
        if [ "$current_count" -ge "$source_count" ]; then
            local end_time=$(date +%s.%N)
            local total_duration=$(echo "$end_time - $start_time" | bc)
            local avg_rate=$(echo "scale=2; $source_count / $total_duration" | bc)
            
            echo ""
            echo ""
            echo -e "${GREEN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
            echo -e "${GREEN}ğŸ‰ Snapshot Sync Complete!${NC}"
            echo -e "${GREEN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
            echo -e "  ğŸ“Š Total Records: $source_count"
            echo -e "  â±ï¸  Total Time: ${total_duration}s"
            echo -e "  ğŸš€ ${CYAN}Average Write Rate: ${avg_rate} records/second${NC}"
            
            # æœ€ç»ˆæ•°æ®å®Œæ•´æ€§éªŒè¯
            echo ""
            echo -e "  ${YELLOW}Verifying data integrity...${NC}"
            local final_sink=$(get_sink_count)
            if [ "$final_sink" -eq "$source_count" ]; then
                echo -e "  ${GREEN}âœ… DATA INTEGRITY: 100% (${final_sink}/${source_count})${NC}"
            else
                echo -e "  ${RED}âŒ DATA LOSS: ${final_sink}/${source_count} records${NC}"
            fi
            
            echo -e "${GREEN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
            return 0
        fi
        
        last_count=$current_count
        sleep $check_interval
        waited=$((waited + check_interval))
    done
    
    echo ""
    echo -e "${RED}âŒ Timeout after ${max_wait}s. Only synced $current_count/$source_count records.${NC}"
    return 1
}


# ä¸»å‡½æ•°
function main() {
    echo -e "${MAGENTA}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
    echo -e "${MAGENTA}â•‘  GaussDB CDC Snapshot Performance Test                     â•‘${NC}"
    echo -e "${MAGENTA}â•‘  Target: $TOTAL_RECORDS records                                      â•‘${NC}"
    echo -e "${MAGENTA}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo ""
    
    # æ­¥éª¤ 1: æ¸…ç†æ•°æ®å’Œæ§½ä½
    cleanup_data
    cleanup_slots
    
    # æ­¥éª¤ 2: æ’å…¥æµ‹è¯•æ•°æ®
    insert_test_data
    
    # æ­¥éª¤ 3: éªŒè¯æ•°æ®åˆ†å¸ƒ
    verify_data_distribution
    
    # æ­¥éª¤ 4: éƒ¨ç½² Flink CDC Job (è§¦å‘å¿«ç…§)
    deploy_flink_job
    
    # æ­¥éª¤ 5: ç­‰å¾… 10 ç§’è®© CDC æµæ¿€æ´»
    echo -e "${YELLOW}â³ Waiting 10s for CDC streams to activate...${NC}"
    sleep 10
    
    # æ­¥éª¤ 6: ç›‘æ§å¿«ç…§åŒæ­¥æ€§èƒ½
    monitor_snapshot_sync
}

main "$@"
